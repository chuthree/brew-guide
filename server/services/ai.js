/**
 * ğŸ¤– AI è°ƒç”¨æœåŠ¡
 *
 * å°è£…ä¸ AI API çš„äº¤äº’é€»è¾‘
 *
 * @module services/ai
 */

import { aiConfig, apiKeys, aiPrompts } from '../config.js';
import logger from '../utils/logger.js';
import { getAIAdapter } from './ai-providers/index.js';

/**
 * è·å– AI é…ç½®
 * ä¼˜å…ˆä½¿ç”¨ clientConfigï¼Œå¦åˆ™ä½¿ç”¨ aiConfig ä¸­çš„é»˜è®¤é…ç½®
 */
function getProviderConfig(clientConfig, type = 'beanRecognition') {
  if (clientConfig && clientConfig.apiKey) {
    return {
      apiKey: clientConfig.apiKey,
      baseURL: clientConfig.apiHost,
      model: clientConfig.model,
      adapterType: clientConfig.type || 'openai',
      // User provided config usually doesn't have internal timeouts/limits defined, use defaults
      timeout: aiConfig[type]?.timeout || 60000,
      maxTokens: aiConfig[type]?.maxTokens || 2000,
      temperature: aiConfig[type]?.temperature || 0.7,
    };
  }

  // Fallback to server config
  const serverConfig = aiConfig[type];
  const apiKey = 
    type === 'beanRecognition' || type === 'methodRecognition' ? apiKeys.qiniu : 
    type === 'yearlyReport' || type === 'feedbackModeration' || type === 'dailyRecommendation' ? apiKeys.siliconflow : 
    '';

  return {
    apiKey,
    baseURL: serverConfig.baseURL,
    model: serverConfig.model,
    adapterType: 'openai', // Server defaults are OpenAI compatible
    timeout: serverConfig.timeout,
    maxTokens: serverConfig.maxTokens,
    temperature: serverConfig.temperature,
  };
}

/**
 * è°ƒç”¨ AI è¯†åˆ«å’–å•¡è±†ï¼ˆæµå¼ï¼‰
 *
 * @param {string} imageUrl - å›¾ç‰‡ Base64 URL
 * @param {Object} [clientConfig] - å®¢æˆ·ç«¯æä¾›çš„ AI é…ç½®
 * @returns {Promise<Stream>} æµå¼å“åº”
 */
export async function recognizeBeanStreaming(imageUrl, clientConfig) {
  const startTime = Date.now();
  const config = getProviderConfig(clientConfig, 'beanRecognition');
  
  logger.info(`ğŸ¤– Starting AI bean recognition (streaming) using ${config.adapterType}...`);

  const adapter = getAIAdapter(config.adapterType);
  
  try {
    const response = await adapter.visionCompletion({
      apiKey: config.apiKey,
      baseURL: config.baseURL,
      model: config.model,
      prompt: aiPrompts.beanRecognition,
      imageUrls: [imageUrl],
      temperature: config.temperature,
      maxTokens: config.maxTokens,
    });

    const duration = Date.now() - startTime;
    logger.logAI(config.model, duration);

    return response;
  } catch (error) {
    logger.error('Bean recognition streaming failed', error);
    throw error;
  }
}

/**
 * è°ƒç”¨ AI è¯†åˆ«å’–å•¡è±†ï¼ˆéæµå¼ï¼‰
 *
 * @param {string} imageUrl - å›¾ç‰‡ Base64 URL
 * @param {Object} [clientConfig] - å®¢æˆ·ç«¯æä¾›çš„ AI é…ç½®
 * @returns {Promise<string>} AI å“åº”å†…å®¹
 */
export async function recognizeBean(imageUrl, clientConfig) {
  const startTime = Date.now();
  const config = getProviderConfig(clientConfig, 'beanRecognition');

  logger.info(`ğŸ¤– Starting AI bean recognition using ${config.adapterType}...`);

  const adapter = getAIAdapter(config.adapterType);

  try {
    const response = await adapter.visionCompletion({
      apiKey: config.apiKey,
      baseURL: config.baseURL,
      model: config.model,
      prompt: aiPrompts.beanRecognition,
      imageUrls: [imageUrl],
      temperature: config.temperature,
      maxTokens: config.maxTokens,
    });

    const duration = Date.now() - startTime;
    logger.logAI(config.model, duration);

    // Adapter returns axios response, need to extract content based on provider
    const data = response.data;
    const content = data.choices?.[0]?.message?.content || 
                    data.candidates?.[0]?.content?.parts?.[0]?.text || // Gemini
                    data.content?.[0]?.text || // Anthropic
                    JSON.stringify(data);

    return content;
  } catch (error) {
    logger.error('Bean recognition failed', error);
    throw error;
  }
}

/**
 * è°ƒç”¨ AI è¯†åˆ«å†²ç…®æ–¹æ¡ˆ
 *
 * @param {string} imageUrl - å›¾ç‰‡ Base64 URL
 * @param {Object} [clientConfig] - å®¢æˆ·ç«¯æä¾›çš„ AI é…ç½®
 * @returns {Promise<string>} AI å“åº”å†…å®¹
 */
export async function recognizeMethod(imageUrl, clientConfig) {
  const startTime = Date.now();
  const config = getProviderConfig(clientConfig, 'methodRecognition');

  logger.info(`ğŸ¤– Starting AI method recognition using ${config.adapterType}...`);

  const adapter = getAIAdapter(config.adapterType);

  try {
    const response = await adapter.visionCompletion({
      apiKey: config.apiKey,
      baseURL: config.baseURL,
      model: config.model,
      prompt: aiPrompts.methodRecognition,
      imageUrls: [imageUrl],
      temperature: config.temperature,
      maxTokens: config.maxTokens,
    });

    const duration = Date.now() - startTime;
    logger.logAI(config.model, duration);

    // Adapter returns axios response, need to extract content based on provider
    const data = response.data;
    const content = data.choices?.[0]?.message?.content || 
                    data.candidates?.[0]?.content?.parts?.[0]?.text || // Gemini
                    data.content?.[0]?.text || // Anthropic
                    JSON.stringify(data);

    return content;
  } catch (error) {
    logger.error('Method recognition failed', error);
    throw error;
  }
}

/**
 * æ™ºèƒ½æ¨èå’–å•¡è±†
 *
 * @param {Array} history - å†å²è®°å½•
 * @param {Array} inventory - åº“å­˜åˆ—è¡¨
 * @param {Object} [clientConfig] - å®¢æˆ·ç«¯ AI é…ç½®
 */
export async function recommendBean(history, inventory, clientConfig) {
  const startTime = Date.now();
  const config = getProviderConfig(clientConfig, 'dailyRecommendation');
  
  logger.info(`ğŸ¤– Starting bean recommendation using ${config.adapterType}...`);

  const adapter = getAIAdapter(config.adapterType);

  // Construct Prompt
  let prompt = '';
  const customPrompt = clientConfig?.prompt;

  if (customPrompt) {
    prompt = customPrompt
      .replace('{{history}}', history.map(h => `- ${h.beanName} (${h.method}): ${h.rating || 'æ— è¯„åˆ†'}`).join('\n'))
      .replace('{{inventory}}', inventory.map(b => `- ${b.name} (id: ${b.id}, ${b.roastLevel || 'æœªçŸ¥çƒ˜ç„™åº¦'}, ${b.process || 'æœªçŸ¥å¤„ç†æ³•'}, ${b.flavors ? 'é£å‘³:' + b.flavors.join(',') : ''}, å‰©ä½™:${b.remaining})`).join('\n'));
  } else {
    // é»˜è®¤ä½¿ç”¨é…ç½®ä¸­çš„ Prompt
    prompt = aiPrompts.dailyRecommendation
      .replace('{{history}}', history.map(h => `- ${h.beanName} (${h.method}): ${h.rating || 'æ— è¯„åˆ†'}`).join('\n'))
      .replace('{{inventory}}', inventory.map(b => `- ${b.name} (id: ${b.id}, ${b.roastLevel || 'æœªçŸ¥çƒ˜ç„™åº¦'}, ${b.process || 'æœªçŸ¥å¤„ç†æ³•'}, ${b.flavors ? 'é£å‘³:' + b.flavors.join(',') : ''}, å‰©ä½™:${b.remaining})`).join('\n'));

    // ç¡®ä¿åŒ…å« JSON æ ¼å¼è¦æ±‚ (å› ä¸º config ä¸­çš„ prompt å·²ç»åŒ…å«äº†è¿™äº›è¦æ±‚ï¼Œè¿™é‡Œä¸å†é‡å¤æ·»åŠ ï¼Œæˆ–è€…ç¡®ä¿ config ä¸­çš„ prompt æ˜¯å®Œæ•´çš„)
    /*
    prompt += `
    
    è¿”å›æ ¼å¼ JSON:
    {
      "beanId": "...",
      "reason": "...",
      "luckyMessage": "..."
    }
    `;
    */
  }

  try {
    const response = await adapter.chatCompletion({
      apiKey: config.apiKey,
      baseURL: config.baseURL,
      model: config.model,
      messages: [
        { role: 'user', content: prompt }
      ],
      temperature: config.temperature,
      maxTokens: config.maxTokens,
      response_format: { type: 'json_object' } // Force JSON if supported
    });

    const duration = Date.now() - startTime;
    logger.logAI(config.model, duration);

    const data = response.data;
    let content = data.choices?.[0]?.message?.content || 
                 data.candidates?.[0]?.content?.parts?.[0]?.text ||
                 data.content?.[0]?.text ||
                 JSON.stringify(data);

    // Clean and Parse JSON
    try {
      const jsonStr = content.replace(/```json\n?|\n?```/g, '').trim();
      return JSON.parse(jsonStr);
    } catch (e) {
      logger.error('Failed to parse AI response:', content);
      throw new Error('AI returned invalid format');
    }
  } catch (error) {
    logger.error('Recommendation failed', error);
    throw error;
  }
}

/**
 * ç”Ÿæˆå¹´åº¦æŠ¥å‘Šï¼ˆæµå¼ï¼‰
 */
export async function generateYearlyReportStreaming(dataSummary, clientConfig) {
  const startTime = Date.now();
  const config = getProviderConfig(clientConfig, 'yearlyReport');

  logger.info(`ğŸ¤– Starting yearly report generation using ${config.adapterType}...`);

  const adapter = getAIAdapter(config.adapterType);

  try {
    const response = await adapter.chatCompletion({
      apiKey: config.apiKey,
      baseURL: config.baseURL,
      model: config.model,
      messages: [
        { role: 'system', content: aiPrompts.yearlyReport },
        { role: 'user', content: dataSummary }
      ],
      stream: true,
      temperature: config.temperature,
      maxTokens: config.maxTokens,
    });

    return response;
  } catch (error) {
    logger.error('Yearly report generation failed', error);
    throw error;
  }
}

/**
 * å†…å®¹å®¡æ ¸ï¼ˆéæµå¼ï¼‰
 */
export async function moderateFeedback(content, clientConfig) {
  const config = getProviderConfig(clientConfig, 'feedbackModeration');
  const adapter = getAIAdapter(config.adapterType);

  try {
    // For moderation we ideally want JSON
    const response = await adapter.chatCompletion({
      apiKey: config.apiKey,
      baseURL: config.baseURL,
      model: config.model,
      messages: [
        { role: 'system', content: aiPrompts.feedbackModeration },
        { role: 'user', content: `è¯·å®¡æ ¸ä»¥ä¸‹ç”¨æˆ·åé¦ˆå†…å®¹ï¼š\n${content}` }
      ],
      temperature: 0.1,
      maxTokens: 100,
      // Only OpenAI supports response_format in this way, others might ignore or need different handling
      responseFormat: config.adapterType === 'openai' ? { type: 'json_object' } : undefined
    });

    const data = response.data;
    const resultText = data.choices?.[0]?.message?.content || 
                       data.candidates?.[0]?.content?.parts?.[0]?.text ||
                       data.content?.[0]?.text ||
                       JSON.stringify(data);
    
    // Attempt to parse JSON
    try {
      // Cleanup cleanup markdown
      const jsonStr = resultText.replace(/```json/g, '').replace(/```/g, '').trim();
      return JSON.parse(jsonStr);
    } catch (e) {
      logger.warn('Failed to parse moderation result JSON', resultText);
      // Fallback check
      const lower = resultText.toLowerCase();
      if (lower.includes('true') || lower.includes('safe')) return { safe: true };
      return { safe: false, reason: 'Parse error' };
    }
  } catch (error) {
    logger.error('Moderation failed', error);
    throw error;
  }
}


